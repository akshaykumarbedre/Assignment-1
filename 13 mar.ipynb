{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a62c5-a294-4af9-ba6b-e7c414122bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\n",
    "it shoud be nomal distubtion\n",
    "absence of outlier\n",
    "homogenity of variance\n",
    "sample are independace\n",
    "\n",
    "ex:\n",
    "    if the outlier has in data , then variance change\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6a8a5-7d2f-4e5e-bcf4-4f9c5a1efac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\n",
    "one way anova : one facter altest 2 level & independence\n",
    "reapeted mean anova:  one facter altest 2 level & dependence\n",
    "factoiral anova: more than 2 facter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938c669-2cbe-45f6-a001-a027a4a60748",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\n",
    "The systematic procedure to achieve this is called Analysis of Variance (ANOVA). With the help of such a comapore more then 2 facter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f24c2f-9f6a-42f7-b33a-c7ae88dddea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 750.0\n",
      "SSE: 600.0\n",
      "SSR: 150.0\n"
     ]
    }
   ],
   "source": [
    "4.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'group1': [10, 20, 30], 'group2': [15, 25, 35], 'group3': [20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate SST\n",
    "grand_mean = df.values.mean()\n",
    "sst = np.sum((df.values - grand_mean)**2)\n",
    "\n",
    "# Calculate SSE\n",
    "sse = 0\n",
    "for col in df.columns:\n",
    "    group_mean = df[col].mean()\n",
    "    sse += np.sum((df[col] - group_mean)**2)\n",
    "\n",
    "# Calculate SSR\n",
    "ssr = sst - sse\n",
    "\n",
    "print('SST:', sst)\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc638fc-e1d5-4fac-8bf8-98aadafe471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\n",
    "mport pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'group1': [10, 20, 30], 'group2': [15, 25, 35], 'group3': [20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate main effects\n",
    "main_effects = {}\n",
    "for col in df.columns:\n",
    "    grand_mean = df.values.mean()\n",
    "    group_mean = df[col].mean()\n",
    "    main_effects[col] = group_mean - grand_mean\n",
    "\n",
    "# Calculate interaction effect\n",
    "interaction_effect = {}\n",
    "for col1 in df.columns:\n",
    "    for col2 in df.columns:\n",
    "        if col1 != col2:\n",
    "            interaction_effect[f'{col1} x {col2}'] = df.groupby([col1, col2]).mean().diff().iloc[-1].sum()\n",
    "\n",
    "print('Main effects:', main_effects)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e92cf1-91dc-4cd4-a570-18a58b201609",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\n",
    "atleast one of the std is not eqaul of a randoum event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2048bd-2d94-4907-93a7-2f7307a7de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.\n",
    "missiing data is filled bt medain or mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d209f0-94ba-4ae9-aee0-f7418312cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "8.\n",
    ". To determine which fertilizers are significantly different from each other, you can use a post-hoc test such as Tukey’s HSD (Honestly Significant Difference) test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58aafe7a-3964-487e-b035-79cfaa8b4591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 2.8888888888888893\n",
      "P-Value: 0.09458508032226556\n"
     ]
    }
   ],
   "source": [
    "9.\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = {'A': [5, 10, 15, 20, 25],\n",
    "        'B': [10, 20, 30, 40, 50],\n",
    "        'C': [15, 25, 35, 45, 55]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct a one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(df['A'], df['B'], df['C'])\n",
    "\n",
    "# Report the F-statistic and p-value\n",
    "print('F-Statistic:', f_statistic)\n",
    "print('P-Value:', p_value)\n",
    "# atleast one of the std is not eqaul of a randoum event\n",
    "# we reject the null hypothesis that there are no significant differences between the mean weight loss of the three diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054fce9f-f8c2-499a-a103-e659de0f3216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          sum_sq   df      F    PR(>F)\n",
      "C(Program)                 96.05  2.0  96.05  0.001907\n",
      "C(Experience)               0.50  1.0   1.00  0.391002\n",
      "C(Program):C(Experience)    4.00  2.0   4.00  0.142427\n",
      "Residual                    1.50  3.0    NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "10. \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = {'Program': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "        'Experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice',\n",
    "                       'Experienced', 'Novice', 'Experienced', 'Novice'],\n",
    "        'Time': [10, 12, 11, 15, 14, 16, 20, 18, 19]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct a two-way ANOVA\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the F-statistics and p-values\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5c4bd-749d-4e47-bd85-54a2483541bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "11.\n",
    "import pandas as pd\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = {'Group': ['Control', 'Experimental'],\n",
    "        'Scores': [85, 90]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct a Tukey HSD test\n",
    "comp = mc.MultiComparison(df['Scores'], df['Group'])\n",
    "post_hoc_res = comp.tukeyhsd()\n",
    "\n",
    "# Report the results\n",
    "print(post_hoc_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2780f369-6f07-416e-89c4-ef81478fe698",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create a dataframe with the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m}\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Conduct a repeated measures ANOVA\u001b[39;00m\n\u001b[1;32m     11\u001b[0m aov \u001b[38;5;241m=\u001b[39m pg\u001b[38;5;241m.\u001b[39mrm_anova(dv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m, within\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m, subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "12.\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "# Create a dataframe with the data\n",
    "data = {'Store': ['A', 'B', 'C'] * 30,\n",
    "        'Sales': [10, 12, 15, 11, 13, 16, 9, 11, 14,10] * 3}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conduct a repeated measures ANOVA\n",
    "aov = pg.rm_anova(dv='Sales', within='Store', subject='Day', data=df)\n",
    "\n",
    "# Report the results\n",
    "print(aov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e66759a-fa80-469c-a801-133ed723a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pingouin\n",
      "  Downloading pingouin-0.5.3-py3-none-any.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting outdated\n",
      "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: seaborn>=0.11 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.12.1)\n",
      "Collecting pandas-flavor>=0.2.0\n",
      "  Downloading pandas_flavor-0.5.0-py3-none-any.whl (7.1 kB)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from pingouin) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.23.5)\n",
      "Requirement already satisfied: statsmodels>=0.13 in /opt/conda/lib/python3.10/site-packages (from pingouin) (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from pingouin) (1.9.3)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.0.2->pingouin) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0->pingouin) (2022.6)\n",
      "Collecting xarray\n",
      "  Downloading xarray-2023.4.2-py3-none-any.whl (979 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.5/979.5 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13->pingouin) (0.5.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (2.28.1)\n",
      "Collecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=44 in /opt/conda/lib/python3.10/site-packages (from outdated->pingouin) (65.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pingouin) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.13->pingouin) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->outdated->pingouin) (2022.12.7)\n",
      "Building wheels for collected packages: littleutils\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=28e11d3c96d833ca5cdd1a9749f88b3dfb46aee9fd9e4ca1b7739d543761119e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/3b/9c/d55ff5bc6cfbe70537c4731a22f2ee2462c2e5010b56ac9726\n",
      "Successfully built littleutils\n",
      "Installing collected packages: littleutils, tabulate, lazy-loader, outdated, xarray, pandas-flavor, pingouin\n",
      "Successfully installed lazy-loader-0.2 littleutils-0.2.2 outdated-0.2.2 pandas-flavor-0.5.0 pingouin-0.5.3 tabulate-0.9.0 xarray-2023.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pingouin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

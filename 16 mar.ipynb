{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81202509-25fd-4e16-961d-d728495d7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\n",
    "overfitting is condition when high accuracy in traing but low accuracy in test\n",
    "underfitting is condition when low accuracy in traing but low accuracy in test\n",
    "by increaing in traing , it can be optiums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfaef1-259b-48cf-9134-6d0e495cd1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\n",
    "Increase training data.\n",
    "Reduce model complexity.\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d565c3-b990-413a-ab0e-f543c4d26cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\n",
    "underfitting is condition when low accuracy in traing but low accuracy in test\n",
    "which has high bias anf high vareance\n",
    "The size of the training dataset used is not enough.\n",
    "The model is too simple.\n",
    "Training data is not cleaned and also contains noise in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc0a92-99a9-4fcd-bac2-b8cc18b609c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.\n",
    "bias is inverly depends on accuracy of training data model\n",
    "variance is inverlty depends of accuracy of testing model\n",
    "underfitting:low bias , high varilance\n",
    "overfittinh :high bias ,high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566c53e-317a-4b5e-afaa-d8f0d3f3d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\n",
    "looking at the prediction error on the training data and the evaluation data\n",
    "by using error in accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f27b0-db11-49c5-88c0-f786aefb9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\n",
    "underfitting:low bias , high variance\n",
    "overfittinh :high bias ,high variance\n",
    "ex:Linear Regression, Linear Discriminant Analysis and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bfef7-aeea-4cb4-b02d-987b08074ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.\n",
    "Regularization is a technique used in machine learning to prevent overfitting and improve the generalization ability of a model1.\n",
    "Overfitting occurs when a model becomes too complex and starts to memorize the training data, leading to poor performance on unseen data1. Regularization adds extra information to the model to prevent overfitting by shrinking the coefficient estimates towards zero\n",
    "There are several regularization techniques that can be used in machine learning such as L1 regularization, L2 regularization, and dropout regularization3.\n",
    "*L1 regularization adds an absolute value of the magnitude of coefficients as a penalty term to the loss function3.\n",
    "*L2 regularization adds a squared magnitude of coefficients as a penalty term to the loss function3.\n",
    "*Dropout regularization randomly drops out some neurons during training3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a6987c-f918-4fd9-9a93-8caa883ebbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\n",
    "Euclidean distance: *it is shortest distance between 2 point\n",
    "formule=sqrt(x2-x1)\n",
    "Manhattan distance:*it is distance between 2 point in  N dimensional vector space\n",
    "formula =abs(x2-x1)\n",
    "*main diff\n",
    "if the data has a high dimensionality, then the Euclidean distance may not be an appropriate choice because it can lead to the curse of dimensionality \n",
    "In such cases, Manhattan distance may be a better choice because it is less sensitive to high-dimensional data 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a2f0a-bf11-4c25-b208-6866fcd33689",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. \n",
    "using hyperparameter we use optimal k value & cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d2bed-741e-486d-98f1-4ba15f12c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\n",
    "if the data has a high dimensionality, then the Euclidean distance may not be an appropriate choice because it can lead to the curse of dimensionality \n",
    "for lower dimesntion, we use Euclidean distance \n",
    "for high dimeasntion, we use Manhattan distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b30ff-c051-4cb7-9965-41a5ab7116bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.classifer & reggestion:n_neighbors,weights,algorithm,p are hyperparamter.\n",
    "n_neighbor: use less , when there less outlier\n",
    "algorithm: it depend on datset\n",
    "p:for lower class we use 2(Euclidean distance)\n",
    "for high class we use 1(Manhattan distance:)\n",
    "using gridserachcv, ramdunserchcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39282768-9320-447f-a286-1fb4cc6c0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\n",
    "if the size of data is low, model can.t performe well\n",
    "if the size is too large , time complexcity is high \n",
    "\n",
    "to fix this , we use cross validation and Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffad18-44d2-4a09-aa5e-b1ecd63b2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\n",
    "curse of dimensionality ,high complesity,  is KNN is sensitive to noisy and missing data \n",
    "we can overcome  the peformace by hyperparmeter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

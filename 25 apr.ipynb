{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Eigenvalues  & Eigenvectors there are non zero value & a vecter when we get by appplying linear tranformation\n",
    "A vectot= alpha vector \n",
    "a=corrvarince matrix \n",
    "alpha contain vecter with diration called eiger diration and value called as Eiger value \n",
    "Eigen-Decomposition is a method of decomposing a square matrix into its eigenvalues and eigenvectors\n",
    "For example, let’s say we have a matrix A = [[1, 2], [2, 1]]. We can find its eigenvalues and eigenvectors by solving the equation Ax = λx. The solution gives us two eigenvalues λ1 = 3 and λ2 = -1 with corresponding eigenvectors v1 = [1/sqrt(2), 1/sqrt(2)] and v2 = [-1/sqrt(2), 1/sqrt(2)] respectively 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\n",
    "Eigen-Decomposition is a method of decomposing a square matrix into its eigenvalues and eigenvectors. \n",
    "*it simplifies the the complex matirx\n",
    "*When the matrix being factorized is a normal or real symmetric matrix, the decomposition is called “spectral decomposition”, derived from the spectral theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\n",
    "A square matrix is diagonalizable if and only if it has n linearly independent eigenvectors 1. In fact, A = PDP^-1, with D a diagonal matrix, if and only if the columns of P are n linearly independent eigenvectors of A. In this case, the diagonal entries of D are eigenvalues of A that correspond, respectively, to the eigenvectors in P 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.The spectral theorem states that any normal matrix can be diagonalized by a unitary matrix . A normal matrix is a matrix that commutes with its conjugate transpose. This theorem is significant in the context of the Eigen-Decomposition approach because it provides a way to decompose a matrix into its eigenvectors and eigenvalues .\n",
    "\n",
    "A square matrix A is diagonalizable if and only if it has n linearly independent eigenvectors. If A is normal, then it can be diagonalized by a unitary matrix U such that U^-1AU = D, where D is a diagonal matrix whose entries are the eigenvalues of A ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\n",
    "Eigenvalues  & Eigenvectors there are non zero value & a vecter when we get by appplying linear tranformation, we can find by applying linear tranformation.\n",
    "it represnt the scaler vecter eqn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\n",
    "eigenvectors is vecter same as corvarincae veter with same direaction.\n",
    "but eigenvalues is float multiple  corvarincae values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.\n",
    "the direaction of eigenvectors & value is same as the diration of corvarincae matrix\n",
    "and value is float multiple of corvarincae matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.\n",
    "it used to PCA\n",
    "it simplifies the the complex matirx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9.\n",
    "it has more then 1 set of value ,however number of dimestion is same as set of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.natural language processing,Principal Component Analysis,Spectral Clustering:\n",
    "Principal Component Analysis (PCA): PCA is a technique used for dimensionality reduction. It uses eigen decomposition to find the eigenvalues and eigenvectors from the dataset and then transforms the data and results in principle components which help in reducing the dimensionality of the data \n",
    "Spectral Clustering: Spectral clustering is a clustering technique that uses eigen decomposition to find the eigenvectors of a similarity matrix. The eigenvectors are then used to cluster the data\n",
    "\n",
    "Latent Semantic Analysis (LSA): LSA is a technique used for natural language processing. It uses eigen decomposition to reduce the dimensionality of the term-document matrix 3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
